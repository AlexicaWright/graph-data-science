[[algorithms-ml-linkprediction-pipelines]]
= Link Prediction Pipelines
:entity: relationship
:result: relationships
//:algorithm: Link Prediction
:modelType: Link prediction pipeline


[abstract]
--
This section describes Link Prediction Pipelines in the Neo4j Graph Data Science library.
--


[[algorithms-ml-linkprediction-pipelines-intro]]
== Introduction

Link prediction is a common machine learning task applied to graphs: training a model to learn, between pairs of nodes in a graph, where relationships should exist.
The GDS library provides Link prediction, see <<algorithms-ml-linkprediction,here>>.
Here we describe an additional method that provides an end-to-end Link prediction experience.
In addition to managing a predictive model, it also manages:

* splitting relationships into subsets for `test`, `train` and `feature input`
* a pipeline of processing steps that supply custom features for the model

The motivation for using pipelines are:

* easier to getting splits right and prevent data leakage
* ensuring that the same feature creation steps are applied in predict and train time
* applying the trained model with a single procedure call
* persisting the pipeline as a whole

The rest of this page is divided as follows:

* <<algorithms-ml-linkprediction-building-a-pipeline, Building a pipeline>>
* <<algorithms-ml-linkprediction-configure-splits, Configuring the relationship splits>>
* <<algorithms-ml-linkprediction-configure-model-parameters, Configuring the model parameters>>
* <<algorithms-ml-linkprediction-pipelines-train, Training and Evaluation>>
* <<algorithms-link-prediction-pipelines-predict, Applying a model for prediction>>

[[algorithms-ml-linkprediction-building-a-pipeline]]
== Building a pipeline

The first step of building a new pipeline is to create it using `gds.alpha.ml.pipeline.linkPrediction.create`.
This stores a trainable model object in the model catalog of type `Link prediction training pipeline`.
This represents a configurable pipeline that can later be invoked for training, which in turn creates a trained pipeline.
The latter is also a model which is stored in the catalog with type `Link prediction pipeline`.

.Create pipeline syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.create(
  pipelineName: String
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureSteps: List of Map,
  splitConfig: Map,
  parameterSpace: List of Map
----

.Results
[opts="header",cols="1,1,6"]
|===
| Name              | Type          | Description
| name              | String        | Name of the pipeline.
| nodePropertySteps | List of Map   | List of configurations for node property steps.
| featureSteps      | List of Map   | List of configurations for feature steps.
| splitConfig       | Map           | Configuration to define the split before the model training.
| parameterSpace    | List of Map   | List of parameter configurations used to select the best model during training from.
|===

=== Example

[role=query-example]
--
.The following will create a pipeline:
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.create('pipe')
----

.Results
[opts="header",cols="1,1,1,1,1"]
|===
| name     | nodePropertySteps | featureSteps | splitConfig | parameterSpace
| "pipe"   | []                | []
           | {negativeSamplingRatio=1.0, testFraction=0.1, validationFolds=3, trainFraction=0.1}
           | [{maxEpochs=100, minEpochs=1, penalty=0.0, patience=1, batchSize=100, tolerance=0.001, concurrency=4}]
|===
--

We can see, the newly created pipeline does not contain any steps yet and only has default for the split and train parameters


[[algorithms-ml-linkprediction-configure-splits]]
== Configuring the relationship splits

Link Prediction pipelines also manage splitting the relationships into several sets and also adds sampled negative relationships to some of these sets.
Configuring the splitting is optional, and if omitted, splitting will be done using default settings.

The splitting of relationships proceeds internally in the following steps:

1. The graph is filtered according to specified `nodeLabels` and `relationshipTypes`, which are configured at train time.
2. The relationships remaining after filtering we call _positive_ and are split into a `test` set and remaining relationships.
* The `test` set contains a `testFraction` fraction of the positive relationships.
* To the `test` set also random negative relationships are added, where the number of negative relationships is the number of positive ones multiplied by the `negativeSamplingRatio`.
* The negative relationships do not coincide with positive relationships.
3. The remaining positive relationships are split into a `train` set and a `feature input` set.
* The `train` set contains a `trainFraction` fraction of _all_ the positive relationships.
** Therefore we require `trainFraction + testFraction < 1.0`.
* To the `train` set also random negative relationships are added, where the number of negative relationships is the number of positive ones multiplied by the `negativeSamplingRatio`.
* The negative relationships do not coincide with positive relationships, nor with test relationships.

The `feature input` graph is used, both in training and testing, for computing node properties and therefore also features which depend on node properties.

The `train` and `test` relationship sets are used for:

* determining the label (positive or negative) for each training or test example
* identifying the node pair for which link features are to be computed

However, they are not used taken into account by the algorithms run in the node property steps.
The reason for this is that otherwise the model would use the prediction target (existence of a relationship) as a feature.


[[algorithms-ml-linkprediction-configure-model-parameters]]
== Configuring the model parameters

[[algorithms-ml-linkprediction-pipelines-train]]
== Training and Evaluation

[[algorithms-link-prediction-pipelines-predict]]
== Applying a model for prediction
// ---------------------------------------------------
//TODO
//Link Prediction can be used favorably together with <<algorithms-ml-models-preprocessing, pre-processing algorithms>>.


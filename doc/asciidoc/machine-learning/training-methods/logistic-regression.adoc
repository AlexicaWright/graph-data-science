[[machine-learning-training-methods-logistic-regression]]
[.beta]
= Logistic regression

Logistic regression is a fundamental supervised machine learning classification method.
This trains a model by minimizing a loss function which depends on a weight matrix and on the training data.
The loss can be minimized for example using gradient descent.
In GDS we use the Adam optimizer which is a gradient descent type algorithm.

The weights are in the form of a `[c,d]` sized matrix `W` and a bias vector `b` of length `c`, where `d` is the feature dimension and `c` is equal to the number of classes.
The loss function is then defined as:

`CE(softmax(Wx + b))`

where `CE` is the https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression[cross entropy loss], `softmax` is the https://en.wikipedia.org/wiki/Softmax_function[softmax function], and `x` is a feature vector training sample of length `d`.

To avoid overfitting one may also add a https://en.wikipedia.org/wiki/Regularization_(mathematics)[regularization] term to the loss.
In GDS, this we provide the option of adding `l2` regularization.


== Tuning the hyperparameters

The parameters `maxEpochs`, `tolerance` and `patience` control for how long the training will run until termination.
These parameters give ways to limit a computational budget. In general, higher `maxEpochs` and `patience` and lower `tolerance` lead to longer training but higher quality models.
It is however well-known that restricting the computational budget can serve the purpose of regularization and mitigate overfitting.

When faced with a heavy training task, a strategy to perform hyperparameter optimization faster, is to initially use lower values for the budget related parameters while exploring better ranges for other general or algorithm specific parameters.

More precisely, `maxEpochs` is the maximum number of epochs trained until termination.
Whether the training exhausted the maximum number of epochs or converged prior is reported in the neo4j debug log.

As for `patience` and `tolerance`, the former is the maximum number of consecutive epochs that do not improve the training loss at least by a `tolerance` fraction of the current loss.
After `patience` such unproductive epochs, the training is terminated.
In our experience, reasonable values for `patience` are in the range `1` to `3`.

It is also possible, via `minEpochs`, to control a minimum number of epochs before the above termination criteria enter into play.

The training algorithm applied to the above algorithms is gradient descent.
The gradients are computed concurrently on batches of `batchSize` samples using `concurrency` many threads.
At the end of an epoch the gradients are summed and scaled before updating the weights.
Therefore `batchSize` and `concurrency` do not affect model quality, but are very useful to tune for training speed.
When updating the weights, we move in the direction dictated by the Adam optimizer based on the loss function's gradients.
How much we move per weights update, you can configure via the `learningRate` parameter.

[[algorithms-ml-linkprediction-pipelines-train]]
== Training and Evaluation

=== Syntax

[.include-with-train]
--
.Run Link Prediction in train mode on a named graph:
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.linkPrediction.train(
  graphName: String,
  configuration: Map
) YIELD
  trainMillis: Integer,
  modelInfo: Map,
  configuration: Map
----

include::../../common-configuration/common-parameters-named-graph.adoc[]

.Configuration
[opts="header",cols="1,1,1m,1,4"]
|===
| Name                                                          | Type              | Default | Optional | Description
| modelName                                                     | String            | n/a     | no       | The name of the model to train, must not exist in the Model Catalog.
| negativeClassWeight                                           | Float             | 1.0     | yes      | Weight of negative examples in model evaluation. Positive examples have weight 1.
| randomSeed                                                    | Integer           | n/a     | yes      | Seed for the random number generator used during training.
| <<common-configuration-node-labels,nodeLabels>>               | List of String    | ['*']   | yes      | Filter the named graph using the given node labels.
| <<common-configuration-relationship-types,relationshipTypes>> | List of String    | ['*']   | yes      | Filter the named graph using the given relationship types.
| <<common-configuration-concurrency,concurrency>>              | Integer           | 4       | yes      | The number of concurrent threads used for running the algorithm.
|===


.Results
[opts="header",cols="1,1,6"]
|===
| Name          | Type    | Description
| trainMillis   | Integer | Milliseconds used for training.
| modelInfo     | Map     | Information about the training and the winning model.
| configuration | Map     | Configuration used for the train procedure.
|===

The `modelInfo` can also be retrieved at a later time by using the <<catalog-model-list, Model List Procedure>>.
The `modelInfo` return field has the following algorithm-specific subfields:

.Model info fields
[opts="header",cols="1,1,6"]
|===
| Name                    | Type          | Description
| bestParameters          | Map           | The model parameters which performed best on average on validation folds according to the primary metric.
| metrics                 | Map           | Map from metric description to evaluated metrics for various models and subsets of the data, see below.
| trainingPipeline        | Map           | The pipeline used for the training.
|===


The structure of `modelInfo` is:

[listing]
----
{
    bestParameters: Map,        // <1>
    trainingPipeline: Map       // <2>
    metrics: {                  // <3>
        AUCPR: {
            test: Float,        // <4>
            outerTrain: Float,  // <5>
            train: [{           // <6>
                avg: Float,
                max: Float,
                min: Float,
                params: Map
            },
            {
                avg: Float,
                max: Float,
                min: Float,
                params: Map
            },
            ...
            ],
            validation: [{      // <7>
                avg: Float,
                max: Float,
                min: Float,
                params: Map
            },
            {
                avg: Float,
                max: Float,
                min: Float,
                params: Map
            },
            ...
            ]
        }
    }
}
----
<1> The best scoring model candidate configuration.
<2> The pipeline used for the training.
<3> The `metrics` map contains an entry for each metric description (currently only `AUCPR`) and the corresponding results for that metric.
<4> Numeric value for the evaluation of the best model on the test set.
<5> Numeric value for the evaluation of the best model on the outer train set.
<6> The `train` entry lists the scores over the `train` set for all candidate models (e.g., `params`). Each such result is in turn also a map with keys `params`, `avg`, `min` and `max`.
<7> The `validation` entry lists the scores over the `validation` set for all candidate models (e.g., `params`). Each such result is in turn also a map with keys `params`, `avg`, `min` and `max`.
--


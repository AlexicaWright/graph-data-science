[[noderegression-pipelines-config]]
= Configuring the pipeline
:max-trials: 10

This page explains how to create and configure a node regression pipeline.
It consists of the following sections:

* <<noderegression-creating-a-pipeline, Creating the pipeline>>
* <<noderegression-pipelines-configure-splits, Configuring the node splits>>
* <<noderegression-pipelines-adding-model-candidates, Adding model candidates>>


[[noderegression-creating-a-pipeline]]
== Creating a pipeline

The first step of building a new pipeline is to create one using `gds.alpha.pipeline.nodeRegression.create`.
This stores a trainable pipeline object in the pipeline catalog of type `Node regression training pipeline`.
This represents a configurable pipeline that can later be invoked for training, which in turn creates a regression model.
The latter is a model which is stored in the catalog with type `NodeRegression`.


=== Syntax

[.pipeline-create-syntax]
--
.Create pipeline syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.pipeline.nodeRegression.create(
  pipelineName: String
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureProperties: List of String,
  splitConfig: Map,
  autoTuningConfig: Map,
  parameterSpace: List of Map
----

.Parameters
[opts="header",cols="1,1,4"]
|===
| Name            | Type    | Description
| pipelineName    | String  | The name of the created pipeline.
|===

include::../pipelineInfoResult.adoc[]
--


=== Example

[role=query-example,group=nr]
--
.The following will create a pipeline:
[source, cypher, role=noplay]
----
CALL gds.alpha.pipeline.nodeRegression.create('pipe')
----

.Results
[opts="header",cols="1,1,1,1,1,1"]
|===
| name     | nodePropertySteps | featureProperties | splitConfig | autoTuningConfig | parameterSpace
| "pipe"   | []                | []
| {testFraction=0.3, validationFolds=3}
| {maxTrials={max-trials}}
| {RandomForest=[], LinearRegression=[]}
|===
--

This shows that the newly created pipeline does not contain any steps yet, and has defaults for the split and train parameters.

// TODO: how much can we share this part?
[[noderegression-pipelines-configure-splits]]
== Configuring the node splits

// TODO link to adding model candidate section
Node Regression Pipelines manage splitting the nodes into several sets for training, testing and validating the models defined in the parameter space.
Configuring the splitting is optional, and if omitted, splitting will be done using default settings.
The splitting configuration of a pipeline can be inspected by using `gds.beta.model.list` and possibly only yielding `splitConfig`.

The node splits are used in the training process as follows:

. The input graph is split into two parts: the train graph and the test graph. See the <<noderegression-pipelines-configure-splits-train-test-image,example below>>.
. The train graph is further divided into a number of validation folds, each consisting of a train part and a validation part. See the <<noderegression-pipelines-configure-splits-validation-image, animation below>>.
. Each model candidate is trained on each train part and evaluated on the respective validation part.
. The model with the highest average score according to the primary metric will win the training.
. The winning model will then be retrained on the entire train graph.
. The winning model is evaluated on the train graph as well as the test graph.
. The winning model is retrained on the entire original graph.

Below we illustrate an example for a graph with 12 nodes.
First we use a `holdoutFraction` of 0.25 to split into train and test subgraphs.

[[noderegression-pipelines-configure-splits-train-test-image]]
image::train-test-splitting/train-test-split.svg[train-test-image,width="500"]

Then we carry out three validation folds, where we first split the train subgraph into 3 disjoint subsets (s1, s2 and s3), and then alternate which subset is used for validation. For each fold, all candidate models are trained in the red nodes, and validated in the green nodes.

[[noderegression-pipelines-configure-splits-validation-image]]
image::train-test-splitting/validation-folds-node-classification.gif[validation-folds-image,width="500"]
// The images were generated using arrows.app. The arrow files are stored in the shared google drive
// in "GDS Team (GDS, Morpheus)/Doc Images/train-test-splitting-illustrations-for-docs"
// The GIF was created in https://ezgif.com/maker/ezgif-3-23bccde0-gif with 150 cs between images and crossfade on


=== Syntax

[.pipeline-configure-split-syntax]
--
.Configure the node split syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.pipeline.nodeRegression.configureSplit(
  pipelineName: String,
  configuration: Map
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureProperties: List of Strings,
  splitConfig: Map,
  autoTuningConfig: Map,
  parameterSpace: List of Map
----

.Parameters
[opts="header",cols="1,1,4"]
|===
| Name            | Type    | Description
| pipelineName    | String  | The name of the pipeline.
| configuration   | Map     | Configuration for splitting the relationships.
|===

.Configuration
[opts="header",cols="1,1,1,4"]
|===
| Name               | Type    | Default | Description
| validationFolds    | Integer | 3       | Number of divisions of the training graph used during <<nodeclassification-pipelines-train,model selection>>.
| testFraction       | Double  | 0.3     | Fraction of the graph reserved for testing. Must be in the range (0, 1). The fraction used for the training is `1 - testFraction`.
|===

include::../pipelineInfoResult.adoc[]
--


=== Example

[role=query-example,group=nr]
--
.The following will configure the splitting of the pipeline:
[source, cypher, role=noplay]
----
CALL gds.alpha.pipeline.nodeRegression.configureSplit('pipe', {
 testFraction: 0.2,
  validationFolds: 5
})
YIELD splitConfig
----

.Results
[opts="header",cols="1"]
|===
| splitConfig
| {testFraction=0.2, validationFolds=5}
|===

// TODO: link to training section here
We now reconfigured the splitting of the pipeline, which will be applied during training.
--

// TODO try share this part with the NC pipeline
[[noderegression-pipelines-adding-model-candidates]]
== Adding model candidates

A pipeline contains a collection of configurations for model candidates which is initially empty.
This collection is called the _parameter space_.
Each model candidate configuration contains either fixed values or ranges for training parameters.
When a range is present, values from the range are determined automatically by an auto-tuning algorithm, see <<ml-auto-tuning>>.
One or more model configurations must be added to the _parameter space_ of the training pipeline, using one of the following procedures:

* `gds.alpha.pipeline.nodeRegression.addLogisticRegression`
* `gds.alpha.pipeline.nodeRegression.addRandomForest`

For information about the available training methods in GDS, logistic regression and random forest, see <<ml-training-methods>>.

// FIXME: add back link to NR train section
In Training the pipeline, we explain further how the configured model candidates are trained, evaluated and compared.

The parameter space of a pipeline can be inspected using `gds.beta.model.list` and optionally yielding only `parameterSpace`.

[NOTE]
====
At least one model candidate must be added to the pipeline before training it.
====


=== Syntax

[.tabbed-example, caption = ]
====
[.include-with-linear-regression]
======
[.pipeline-add-lr-syntax]
--
.Configure the train parameters syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.pipeline.nodeRegression.addLinearRegression(
  pipelineName: String,
  config: Map
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureProperties: List of String,
  splitConfig: Map,
  autoTuningConfig: Map,
  parameterSpace: Map
----

.Parameters
[opts="header",cols="1,1,4"]
|===
| Name            | Type        | Description
| pipelineName    | String      | The name of the pipeline.
| config          | Map         | The logistic regression config for a potential model. The allowed parameters for a model are defined in the next table.
|===

include::../../training-methods/linearRegressionConfig.adoc[]

include::../pipelineInfoResult.adoc[]
--
======

[.include-with-random-forest]
======

[.pipeline-add-rf-syntax]
--
.Configure the train parameters syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.pipeline.nodeClassification.addRandomForest(
  pipelineName: String,
  config: Map
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureProperties: List of String,
  splitConfig: Map,
  autoTuningConfig: Map,
  parameterSpace: Map
----

.Parameters
[opts="header",cols="1,1,4"]
|===
| Name            | Type        | Description
| pipelineName    | String      | The name of the pipeline.
| config          | Map         | The random forest config for a potential model. The allowed parameters for a model are defined in the next table.
|===

include::../../training-methods/randomForestConfig.adoc[]

include::../pipelineInfoResult.adoc[]
--
======
====


=== Example

We can add multiple model candidates to our pipeline.

[source, cypher, role=noplay query-example, no-result=true, group=nr]
.The following will add a linear regression model with default configuration:
--
CALL gds.alpha.pipeline.nodeRegression.addLinearRegression('pipe')
YIELD parameterSpace
--

[source, cypher, role=noplay query-example, no-result=true, group=nr]
.The following will add a random forest model:
--
CALL gds.alpha.pipeline.nodeRegression.addRandomForest('pipe', {numberOfDecisionTrees: 5})
YIELD parameterSpace
--

[role=query-example,group=nr]
--
.The following will add a linear regression model with a range parameter:
[source, cypher, role=noplay]
----
CALL gds.alpha.pipeline.nodeRegression.addLinearRegression('pipe', {maxEpochs: 500, penalty: {range: [1e-4, 1e2]}})
YIELD parameterSpace
RETURN parameterSpace.RandomForest AS randomForestSpace, parameterSpace.LinearRegression AS linearRegressionSpace
----

.Results
[opts="header",cols="1, 1"]
|===
| randomForestSpace | linearRegressionSpace
| [{maxDepth=2147483647, minSplitSize=2, numberOfDecisionTrees=5, methodName=RandomForest, numberOfSamplesRatio=1.0}] | [{maxEpochs=100, minEpochs=1, penalty=0.0, patience=1, methodName=LinearRegression, batchSize=100, tolerance=0.001, learningRate=0.001}, {maxEpochs=500, minEpochs=1, penalty={range=[1.0E-4, 100.0]}, patience=1, methodName=LinearRegression, batchSize=100, tolerance=0.001, learningRate=0.001}]
|===
--

//FIXME add link to training section
The `parameterSpace` in the pipeline now contains the three different model candidates, expanded with the default values.
Each specified model candidate will be tried out during the model selection in trainin.

[NOTE]
====
These are somewhat naive examples of how to add and configure model candidates.
Please see <<ml-training-methods>> for more information on how to tune the configuration parameters of each method.
====

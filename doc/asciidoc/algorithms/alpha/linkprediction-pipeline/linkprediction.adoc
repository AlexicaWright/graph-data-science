[[algorithms-ml-linkprediction-pipelines]]
= Link Prediction Pipelines
:entity: relationship
:result: relationships
//:algorithm: Link Prediction
:modelType: Link prediction pipeline


[abstract]
--
This section describes Link Prediction Pipelines in the Neo4j Graph Data Science library.
--


[[algorithms-ml-linkprediction-pipelines-intro]]
== Introduction

Link prediction is a common machine learning task applied to graphs: training a model to learn, between pairs of nodes in a graph, where relationships should exist.
More precisely, the input of the machine learning model are _examples_ of node pairs which are labeled as connected or not connected.
The GDS library provides Link prediction, see <<algorithms-ml-linkprediction,here>>.
Here we describe an additional method that provides an end-to-end Link prediction experience.
In addition to managing a predictive model, it also manages:

* splitting relationships into subsets for `test`, `train` and `feature input`
* a pipeline of processing steps that supply custom features for the model

The motivation for using pipelines are:

* easier to getting splits right and prevent data leakage
* ensuring that the same feature creation steps are applied in predict and train time
* applying the trained model with a single procedure call
* persisting the pipeline as a whole

The rest of this page is divided as follows:

* <<algorithms-ml-linkprediction-creating-a-pipeline, Creating a pipeline>>
* <<algorithms-ml-linkprediction-adding-node-properties, Adding node properties>>
* <<algorithms-ml-linkprediction-adding-features, Adding link features>>
* <<algorithms-ml-linkprediction-configure-splits, Configuring the relationship splits>>
* <<algorithms-ml-linkprediction-configure-model-parameters, Configuring the model parameters>>
* <<algorithms-ml-linkprediction-pipelines-train, Training and Evaluation>>
* <<algorithms-link-prediction-pipelines-predict, Applying a model for prediction>>

[[algorithms-ml-linkprediction-creating-a-pipeline]]
== Creating a pipeline

The first step of building a new pipeline is to create it using `gds.alpha.ml.pipeline.linkPrediction.create`.
This stores a trainable model object in the model catalog of type `Link prediction training pipeline`.
This represents a configurable pipeline that can later be invoked for training, which in turn creates a trained pipeline.
The latter is also a model which is stored in the catalog with type `Link prediction pipeline`.

=== Syntax

[.pipeline-create-syntax]
--
.Create pipeline syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.create(
  pipelineName: String
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureSteps: List of Map,
  splitConfig: Map,
  parameterSpace: List of Map
----

.Parameters
[opts="header",cols="1,1,4"]
|===
| Name            | Type   | Description
| pipelineName    | String  | The name of the created pipeline.
|===

include::pipelineInfoResult.adoc[]
--

=== Example

[role=query-example,group=lp]
--
.The following will create a pipeline:
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.create('pipe')
----

.Results
[opts="header",cols="1,1,1,1,1"]
|===
| name     | nodePropertySteps | featureSteps | splitConfig | parameterSpace
| "pipe"   | []                | []
           | {negativeSamplingRatio=1.0, testFraction=0.1, validationFolds=3, trainFraction=0.1}
           | [{maxEpochs=100, minEpochs=1, penalty=0.0, patience=1, batchSize=100, tolerance=0.001, concurrency=4}]
|===
--

We can see, the newly created pipeline does not contain any steps yet and only has default for the split and train parameters

[[algorithms-ml-linkprediction-adding-node-properties]]
== Adding node properties

A link prediction pipeline can execute one or several GDS algorithms in mutate mode that create node properties in the in-memory graph.
Such steps producing node properties can be chained one after another and created properties can also be used to <<algorithms-ml-linkprediction-adding-features, add features>>.
Moreover, the node property steps that are added to the pipeline will be executed both when <<algorithms-ml-linkprediction-pipelines-train, training>> a model and when the trained model is <<algorithms-link-prediction-pipelines-predict, applied for prediction>>.

The name of the procedure that should be added can be a fully GDS procedure name ending with `.mutate`.
The ending `.mutate` may be omitted and one may also use shorthand forms such as `node2vec` instead of `gds.beta.node2vec.mutate`.

It can be favorable to include <<algorithms-ml-models-preprocessing, pre-processing algorithms>> as node property steps.

=== Syntax

[.pipeline-add-node-property-syntax]
--
.Add node property syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.addNodeProperty(
  pipelineName: String,
  procedureName: String,
  procedureConfiguration: Map
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureSteps: List of Map,
  splitConfig: Map,
  parameterSpace: List of Map
----

.Parameters
[opts="header",cols="1,1,4"]
|===
| Name                      | Type    | Description
| pipelineName              | String  | The name of the pipeline.
| procedureName             | String  | The name of the the procedure to be added to the pipeline.
| procedureConfiguration    | Map     | The configuration of the procedure, excluding `graphName`, `nodeLabels` and `relationshipTypes`.
|===

include::pipelineInfoResult.adoc[]
--
=== Example

[role=query-example,group=lp]
--
.The following will add a node property step to the pipeline:
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.addNodeProperty('pipe', 'fastRP', {mutateProperty: 'embedding', embeddingDimension: 256})
----

.Results
[opts="header",cols="1,1,1,1,1"]
|===
| name     | nodePropertySteps | featureSteps | splitConfig | parameterSpace
| "pipe"   | [{name=fastRP, config={embeddingDimension=256, mutateProperty=embedding}}]
| []
| {negativeSamplingRatio=1.0, testFraction=0.1, validationFolds=3, trainFraction=0.1}
| [{maxEpochs=100, minEpochs=1, penalty=0.0, patience=1, batchSize=100, tolerance=0.001, concurrency=4}]
|===
--


[[algorithms-ml-linkprediction-adding-features]]
== Adding link features

A Link Prediction pipeline executes a sequence of steps to compute the features used by a machine learning model.
A feature step computes a vector of features for given node pairs.
For each node pair, the results are concatenated into a single _link feature vector_.
The order of the features in the link feature vector follows the order of the feature steps.
Like with node property steps, the feature steps are also executed both at <<algorithms-ml-linkprediction-pipelines-train, training>> and <<algorithms-link-prediction-pipelines-predict, prediction>> time.
The supported methods for obtaining features are described <<algorithms-ml-linkprediction-supported-features, below>>

=== Syntax

[.pipeline-add-feature-syntax]
--
.Adding a link feature to a pipeline syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.addFeature(
  pipelineName: String,
  featureType: String,
  configuration: Map
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureSteps: List of Map,
  splitConfig: Map,
  parameterSpace: List of Map
----

.Parameters
[opts="header",cols="1,1,4"]
|===
| Name                   | Type    | Description
| pipelineName           | String  | The name of the pipeline.
| featureType            | String  | The featureType determines the method used for computing the link feature. See <<algorithms-ml-linkprediction-supported-features, supported types>>.
| configuration          | Map     | Configuration for splitting the relationships.
|===

.Configuration
[opts="header",cols="1,1,1,4"]
|===
| Name              | Type              | Default | Description
| nodeProperties    | List of String    | no      | The names of the node properties that should be used as input.
|===

include::pipelineInfoResult.adoc[]
--

[[algorithms-ml-linkprediction-supported-features]]
=== Supported feature types

A feature step can use node properties that exist in the input graph or are added by the pipeline.
For each node in a node pair of interest, the values of `nodeProperties` are concatenated, in the configured order, into a vector.
We denote the entries of the vectors of a pair by `a[i]` and `b[i]`, and we take `f[i]` to be the `i`-th entry of the output of a feature step.

The supported types of features can then be described as follows:

.Supported feature types
[opts="header",cols="1,4"]
|===
| Feature Type           | Formula / Description
| L2                     | f[i] = (a[i] - b[i])^2
| HADAMARD               | f[i] = a[i] * b[i]
| COSINE                 | f[0] = cosine similarity of vectors a and b
|===

=== Example

[role=query-example,group=lp]
--
.The following will add a feature step to the pipeline:
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.addFeature('pipe', 'hadamard', {
  nodeProperties: ['embedding', 'numberOfPosts']
}) YIELD featureSteps
----

.Results
[opts="header",cols="1"]
|===
| featureSteps
| [{name=HADAMARD, config={nodeProperties=[embedding, numberOfPosts]}}]
|===

When executing the pipeline, the `nodeProperties` must be either present in the input graph, or created by a previous node property step.
For example, the `embedding` property could be created by the previous example, and we expect `numberOfPosts` to be present at train and predict time.
--

[[algorithms-ml-linkprediction-configure-splits]]
== Configuring the relationship splits

Link Prediction pipelines also manage splitting the relationships into several sets and also adds sampled negative relationships to some of these sets.
Configuring the splitting is optional, and if omitted, splitting will be done using default settings.

The splitting of relationships proceeds internally in the following steps:

1. The graph is filtered according to specified `nodeLabels` and `relationshipTypes`, which are configured at train time.
2. The relationships remaining after filtering we call _positive_ and are split into a `test` set and remaining relationships.
* The `test` set contains a `testFraction` fraction of the positive relationships.
* To the `test` set also random negative relationships are added, where the number of negative relationships is the number of positive ones multiplied by the `negativeSamplingRatio`.
* The negative relationships do not coincide with positive relationships.
3. The remaining positive relationships are split into a `train` set and a `feature input` set.
* The `train` set contains a `trainFraction` fraction of _all_ the positive relationships.
** Therefore we require `trainFraction + testFraction < 1.0`.
* To the `train` set also random negative relationships are added, where the number of negative relationships is the number of positive ones multiplied by the `negativeSamplingRatio`.
* The negative relationships do not coincide with positive relationships, nor with test relationships.

The `feature input` graph is used, both in training and testing, for computing node properties and therefore also features which depend on node properties.

The `train` and `test` relationship sets are used for:

* determining the label (positive or negative) for each training or test example
* identifying the node pair for which link features are to be computed

However, they are not used taken into account by the algorithms run in the node property steps.
The reason for this is that otherwise the model would use the prediction target (existence of a relationship) as a feature.

=== Syntax

[.pipeline-configure-split-syntax]
--
.Configure the relationship split syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.configureSplit(
  pipelineName: String,
  configuration: Map
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureSteps: List of Map,
  splitConfig: Map,
  parameterSpace: List of Map
----

.Parameters
[opts="header",cols="1,1,4"]
|===
| Name            | Type    | Description
| pipelineName    | String  | The name of the pipeline.
| configuration   | Map     | Configuration for splitting the relationships.
|===

.Configuration
[opts="header",cols="1,1,1,4"]
|===
| Name                  | Type    | Default | Description
| validationFolds       | Integer | 3       | Number of divisions of the training graph used during model selection.
| testFraction          | Double  | 0.1     | Portion of the graph reserved for testing. Must be in the range (0, 1).
| trainFraction         | Double  | 0.1     | Portion of the graph reserved for training. Must be in the range (0, 1).
| negativeSamplingRatio | Double  | 1.0     | The desired ratio of negative to positive samples in the test and train set.
|===

include::pipelineInfoResult.adoc[]
--

=== Example

[role=query-example,group=lp]
--
.The following will configure the splitting of the pipeline:
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.configureSplit('pipe', {testFraction: 0.3, trainFraction: 0.3, validationFolds: 7})
YIELD splitConfig
----

.Results
[opts="header",cols="1"]
|===
| splitConfig
| {negativeSamplingRatio=1.0, testFraction=0.3, validationFolds=7, trainFraction=0.3}
|===
--

[[algorithms-ml-linkprediction-configure-model-parameters]]
== Configuring the model parameters

=== Syntax

[.pipeline-configure-params-syntax]
--
.Configure the train parameters syntax
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.configureParams(
  pipelineName: String,
  parameterSpace: List of Map
)
YIELD
  name: String,
  nodePropertySteps: List of Map,
  featureSteps: List of Map,
  splitConfig: Map,
  parameterSpace: List of Map
----

.Parameters
[opts="header",cols="1,1,4"]
|===
| Name            | Type        | Description
| pipelineName    | String      | The name of the pipeline.
| parameterSpace  | List of Map | The parameter space used to select the best model from. Each Map corresponds to potential model. The allowed parameters for a model are defined in the next table.
|===

.Model configuration
[opts="header",cols="1,1,1m,1,4"]
|===
| Name                | Type    | Default         | Optional | Description
| penalty             | Float   | 0.0             | yes      | Penalty used for the logistic regression. By default, no penalty is applied.
| batchSize           | Integer | 100             | yes      | Number of nodes per batch.
| minEpochs           | Integer | 1               | yes      | Minimum number of training epochs.
| maxEpochs           | Integer | 100             | yes      | Maximum number of training epochs.
| patience            | Integer | 1               | yes      | Maximum number of unproductive consecutive epochs.
| tolerance           | Float   | 0.001           | yes      | The minimal improvement of the loss to be considered productive.
| concurrency         | Integer | see description | yes      | Concurrency for training the model candidate. By default, the value of `concurrency` defined at training is used.
|===

include::pipelineInfoResult.adoc[]
--

=== Example

[role=query-example,group=lp]
--
.The following will configure the parameter space of the pipeline:
[source, cypher, role=noplay]
----
CALL gds.alpha.ml.pipeline.linkPrediction.configureParams('pipe',
  [{tolerance: 0.001}, {tolerance: 0.01}, {maxEpochs: 500}]
) YIELD parameterSpace
----

.Results
[opts="header",cols="1"]
|===
| parameterSpace
| [{maxEpochs=100, minEpochs=1, penalty=0.0, patience=1, batchSize=100, tolerance=0.001}, {maxEpochs=100, minEpochs=1, penalty=0.0, patience=1, batchSize=100, tolerance=0.01}, {maxEpochs=500, minEpochs=1, penalty=0.0, patience=1, batchSize=100, tolerance=0.001}]
|===
--

include::trainAndEval.adoc[]

include::predict.adoc[]
